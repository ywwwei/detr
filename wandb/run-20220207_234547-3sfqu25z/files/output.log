
| distributed init (rank 0): env://
number of params: 53942958
loading annotations into memory...
Done (t=11.48s)
creating index...
index created!
train   22275  measurements
loading annotations into memory...
Done (t=1.84s)
creating index...
index created!
val   687  measurements
Start training
Epoch: [0]  [  0/125]  eta: 0:01:56  lr: 0.000100  class_error: 100.00  loss: 49.7484 (49.7484)  loss_bbox: 3.3983 (3.3983)  loss_bbox_0: 3.5644 (3.5644)  loss_bbox_1: 3.4659 (3.4659)  loss_bbox_2: 3.4236 (3.4236)  loss_bbox_3: 3.5650 (3.5650)  loss_bbox_4: 3.4377 (3.4377)  loss_ce: 3.6371 (3.6371)  loss_ce_0: 3.4354 (3.4354)  loss_ce_1: 3.1081 (3.1081)  loss_ce_2: 3.4085 (3.4085)  loss_ce_3: 3.4448 (3.4448)  loss_ce_4: 3.7922 (3.7922)  loss_giou: 1.3297 (1.3297)  loss_giou_0: 1.3781 (1.3781)  loss_giou_1: 1.3683 (1.3683)  loss_giou_2: 1.3263 (1.3263)  loss_giou_3: 1.3580 (1.3580)  loss_giou_4: 1.3070 (1.3070)  cardinality_error_unscaled: 97.5000 (97.5000)  cardinality_error_0_unscaled: 97.0000 (97.0000)  cardinality_error_1_unscaled: 90.5000 (90.5000)  cardinality_error_2_unscaled: 98.0000 (98.0000)  cardinality_error_3_unscaled: 95.5000 (95.5000)  cardinality_error_4_unscaled: 97.7500 (97.7500)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.6797 (0.6797)  loss_bbox_0_unscaled: 0.7129 (0.7129)  loss_bbox_1_unscaled: 0.6932 (0.6932)  loss_bbox_2_unscaled: 0.6847 (0.6847)  loss_bbox_3_unscaled: 0.7130 (0.7130)  loss_bbox_4_unscaled: 0.6875 (0.6875)  loss_ce_unscaled: 3.6371 (3.6371)  loss_ce_0_unscaled: 3.4354 (3.4354)  loss_ce_1_unscaled: 3.1081 (3.1081)  loss_ce_2_unscaled: 3.4085 (3.4085)  loss_ce_3_unscaled: 3.4448 (3.4448)  loss_ce_4_unscaled: 3.7922 (3.7922)  loss_giou_unscaled: 0.6649 (0.6649)  loss_giou_0_unscaled: 0.6891 (0.6891)  loss_giou_1_unscaled: 0.6842 (0.6842)  loss_giou_2_unscaled: 0.6632 (0.6632)  loss_giou_3_unscaled: 0.6790 (0.6790)  loss_giou_4_unscaled: 0.6535 (0.6535)  time: 0.9311  data: 0.1034  max mem: 1074
Epoch: [0]  [ 10/125]  eta: 0:00:34  lr: 0.000100  class_error: 100.00  loss: 41.1961 (40.7347)  loss_bbox: 4.0538 (4.0299)  loss_bbox_0: 4.2030 (4.0718)  loss_bbox_1: 4.1709 (4.0674)  loss_bbox_2: 4.1286 (4.0421)  loss_bbox_3: 4.0830 (4.0362)  loss_bbox_4: 4.0630 (4.0542)  loss_ce: 0.7863 (1.0731)  loss_ce_0: 0.8188 (1.1232)  loss_ce_1: 0.8356 (1.0337)  loss_ce_2: 0.8735 (1.0747)  loss_ce_3: 0.7863 (1.0852)  loss_ce_4: 0.7907 (1.0751)  loss_giou: 1.6158 (1.6463)  loss_giou_0: 1.6638 (1.6841)  loss_giou_1: 1.7063 (1.6819)  loss_giou_2: 1.6568 (1.6641)  loss_giou_3: 1.6060 (1.6515)  loss_giou_4: 1.6161 (1.6401)  cardinality_error_unscaled: 1.2500 (10.1136)  cardinality_error_0_unscaled: 1.2500 (10.0682)  cardinality_error_1_unscaled: 1.2500 (9.4773)  cardinality_error_2_unscaled: 1.2500 (10.1591)  cardinality_error_3_unscaled: 1.2500 (9.9318)  cardinality_error_4_unscaled: 1.2500 (10.1364)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.8108 (0.8060)  loss_bbox_0_unscaled: 0.8406 (0.8144)  loss_bbox_1_unscaled: 0.8342 (0.8135)  loss_bbox_2_unscaled: 0.8257 (0.8084)  loss_bbox_3_unscaled: 0.8166 (0.8072)  loss_bbox_4_unscaled: 0.8126 (0.8108)  loss_ce_unscaled: 0.7863 (1.0731)  loss_ce_0_unscaled: 0.8188 (1.1232)  loss_ce_1_unscaled: 0.8356 (1.0337)  loss_ce_2_unscaled: 0.8735 (1.0747)  loss_ce_3_unscaled: 0.7863 (1.0852)  loss_ce_4_unscaled: 0.7907 (1.0751)  loss_giou_unscaled: 0.8079 (0.8232)  loss_giou_0_unscaled: 0.8319 (0.8420)  loss_giou_1_unscaled: 0.8531 (0.8409)  loss_giou_2_unscaled: 0.8284 (0.8321)  loss_giou_3_unscaled: 0.8030 (0.8258)  loss_giou_4_unscaled: 0.8080 (0.8200)  time: 0.3041  data: 0.0674  max mem: 1456
Epoch: [0]  [ 20/125]  eta: 0:00:28  lr: 0.000100  class_error: 100.00  loss: 37.4558 (38.7643)  loss_bbox: 3.9245 (3.9123)  loss_bbox_0: 3.8357 (3.9142)  loss_bbox_1: 3.9258 (3.9201)  loss_bbox_2: 3.8916 (3.9039)  loss_bbox_3: 3.9526 (3.9090)  loss_bbox_4: 3.8773 (3.9216)  loss_ce: 0.7863 (0.9393)  loss_ce_0: 0.8188 (0.9710)  loss_ce_1: 0.8151 (0.9160)  loss_ce_2: 0.8205 (0.9438)  loss_ce_3: 0.7863 (0.9408)  loss_ce_4: 0.7907 (0.9339)  loss_giou: 1.6157 (1.5956)  loss_giou_0: 1.6473 (1.6262)  loss_giou_1: 1.6349 (1.6150)  loss_giou_2: 1.6145 (1.6051)  loss_giou_3: 1.6031 (1.5992)  loss_giou_4: 1.5908 (1.5972)  cardinality_error_unscaled: 1.2500 (5.9405)  cardinality_error_0_unscaled: 1.2500 (5.9167)  cardinality_error_1_unscaled: 1.2500 (5.6071)  cardinality_error_2_unscaled: 1.2500 (5.9643)  cardinality_error_3_unscaled: 1.2500 (5.8452)  cardinality_error_4_unscaled: 1.2500 (5.9524)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.7849 (0.7825)  loss_bbox_0_unscaled: 0.7671 (0.7828)  loss_bbox_1_unscaled: 0.7852 (0.7840)  loss_bbox_2_unscaled: 0.7783 (0.7808)  loss_bbox_3_unscaled: 0.7905 (0.7818)  loss_bbox_4_unscaled: 0.7755 (0.7843)  loss_ce_unscaled: 0.7863 (0.9393)  loss_ce_0_unscaled: 0.8188 (0.9710)  loss_ce_1_unscaled: 0.8151 (0.9160)  loss_ce_2_unscaled: 0.8205 (0.9438)  loss_ce_3_unscaled: 0.7863 (0.9408)  loss_ce_4_unscaled: 0.7907 (0.9339)  loss_giou_unscaled: 0.8078 (0.7978)  loss_giou_0_unscaled: 0.8237 (0.8131)  loss_giou_1_unscaled: 0.8175 (0.8075)  loss_giou_2_unscaled: 0.8072 (0.8026)  loss_giou_3_unscaled: 0.8016 (0.7996)  loss_giou_4_unscaled: 0.7954 (0.7986)  time: 0.2401  data: 0.0658  max mem: 1456
Error in sys.excepthook:
Traceback (most recent call last):
  File "/u/y/i/yibingwei/anaconda3/envs/vistr/lib/python3.7/linecache.py", line 47, in getlines
    return updatecache(filename, module_globals)
  File "/u/y/i/yibingwei/anaconda3/envs/vistr/lib/python3.7/linecache.py", line 136, in updatecache
    with tokenize.open(fullname) as fp:
  File "/u/y/i/yibingwei/anaconda3/envs/vistr/lib/python3.7/tokenize.py", line 450, in open
    buffer.seek(0)
KeyboardInterrupt
Original exception was:
Traceback (most recent call last):
  File "main.py", line 290, in <module>
    main(args)
  File "main.py", line 227, in main
    args.clip_max_norm)
  File "/afs/cs.wisc.edu/u/y/i/yibingwei/detr/engine.py", line 57, in train_one_epoch
    optimizer.step()
  File "/u/y/i/yibingwei/anaconda3/envs/vistr/lib/python3.7/site-packages/torch/optim/lr_scheduler.py", line 65, in wrapper
    return wrapped(*args, **kwargs)
  File "/u/y/i/yibingwei/anaconda3/envs/vistr/lib/python3.7/site-packages/torch/optim/optimizer.py", line 88, in wrapper
    return func(*args, **kwargs)
  File "/u/y/i/yibingwei/anaconda3/envs/vistr/lib/python3.7/site-packages/torch/autograd/grad_mode.py", line 28, in decorate_context
    return func(*args, **kwargs)
  File "/u/y/i/yibingwei/anaconda3/envs/vistr/lib/python3.7/site-packages/torch/optim/adamw.py", line 148, in step
    eps=group['eps'])
  File "/u/y/i/yibingwei/anaconda3/envs/vistr/lib/python3.7/site-packages/torch/optim/_functional.py", line 131, in adamw
    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)
KeyboardInterrupt